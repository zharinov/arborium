//! CI workflow generation for GitHub Actions.
//!
//! This module generates a single unified workflow that handles both CI and releases.
//! On regular pushes/PRs, it runs tests. On tag pushes, it also publishes.

use facet::Facet;
use indexmap::IndexMap;

use crate::plugins::{PluginGroups, PluginTimings};

// =============================================================================
// GitHub Actions Workflow Schema
// =============================================================================

structstruck::strike! {
    /// A GitHub Actions workflow file.
    #[strikethrough[derive(Debug, Clone, Facet)]]
    #[facet(rename_all = "kebab-case")]
    pub struct Workflow {
        /// The name of the workflow displayed in the GitHub UI.
        pub name: String,

        /// The events that trigger the workflow.
        pub on: On,

        /// Environment variables available to all jobs.
        #[facet(default, skip_serializing_if = Option::is_none)]
        pub env: Option<IndexMap<String, String>>,

        /// The jobs that make up the workflow.
        pub jobs: IndexMap<String, Job>,
    }
}

structstruck::strike! {
    /// Events that trigger a workflow.
    #[strikethrough[derive(Debug, Clone, Facet)]]
    #[facet(rename_all = "snake_case")]
    pub struct On {
        /// Trigger on push events.
        #[facet(default, skip_serializing_if = Option::is_none)]
        pub push: Option<pub struct PushTrigger {
            /// Branches to trigger on.
            #[facet(default, skip_serializing_if = Option::is_none)]
            pub branches: Option<Vec<String>>,
            /// Tags to trigger on.
            #[facet(default, skip_serializing_if = Option::is_none)]
            pub tags: Option<Vec<String>>,
        }>,

        /// Trigger on pull request events.
        #[facet(default, skip_serializing_if = Option::is_none)]
        pub pull_request: Option<pub struct PullRequestTrigger {
            /// Branches to trigger on.
            #[facet(default, skip_serializing_if = Option::is_none)]
            pub branches: Option<Vec<String>>,
        }>,

        /// Trigger on merge group events.
        #[facet(default, skip_serializing_if = Option::is_none)]
        pub merge_group: Option<pub struct MergeGroupTrigger {}>,

        /// Trigger on workflow_dispatch (manual).
        #[facet(default, skip_serializing_if = Option::is_none)]
        pub workflow_dispatch: Option<pub struct WorkflowDispatchTrigger {
            /// Input parameters.
            #[facet(default, skip_serializing_if = Option::is_none)]
            pub inputs: Option<IndexMap<String, WorkflowInput>>,
        }>,
    }
}

structstruck::strike! {
    /// A workflow input parameter.
    #[strikethrough[derive(Debug, Clone, Facet)]]
    #[facet(rename_all = "snake_case")]
    pub struct WorkflowInput {
        /// Description of the input.
        pub description: String,
        /// Whether the input is required.
        #[facet(default)]
        pub required: bool,
        /// The type of input.
        #[facet(rename = "type")]
        pub input_type: String,
        /// Default value.
        #[facet(default, skip_serializing_if = Option::is_none)]
        pub default: Option<String>,
    }
}

structstruck::strike! {
    /// A job in a workflow.
    #[strikethrough[derive(Debug, Clone, Facet)]]
    #[facet(rename_all = "kebab-case")]
    pub struct Job {
        /// Display name for the job in the GitHub UI.
        #[facet(default, skip_serializing_if = Option::is_none)]
        pub name: Option<String>,

        /// The runner to use.
        pub runs_on: String,

        /// Container to run the job in.
        #[facet(default, skip_serializing_if = Option::is_none)]
        pub container: Option<String>,

        /// Jobs that must complete before this one.
        #[facet(default, skip_serializing_if = Option::is_none)]
        pub needs: Option<Vec<String>>,

        /// Outputs from this job.
        #[facet(default, skip_serializing_if = Option::is_none)]
        pub outputs: Option<IndexMap<String, String>>,

        /// Condition for running this job.
        #[facet(default, skip_serializing_if = Option::is_none, rename = "if")]
        pub if_condition: Option<String>,

        /// The steps to run.
        pub steps: Vec<Step>,
    }
}

structstruck::strike! {
    /// A step in a job.
    #[strikethrough[derive(Debug, Clone, Facet)]]
    #[facet(rename_all = "kebab-case")]
    pub struct Step {
        /// The name of the step.
        #[facet(default, skip_serializing_if = Option::is_none)]
        pub name: Option<String>,

        /// Use a GitHub Action.
        #[facet(default, skip_serializing_if = Option::is_none)]
        pub uses: Option<String>,

        /// Run a shell command.
        #[facet(default, skip_serializing_if = Option::is_none)]
        pub run: Option<String>,

        /// Inputs for the action.
        #[facet(default, skip_serializing_if = Option::is_none)]
        pub with: Option<IndexMap<String, String>>,

        /// Environment variables for this step.
        #[facet(default, skip_serializing_if = Option::is_none)]
        pub env: Option<IndexMap<String, String>>,

        /// Step ID for referencing outputs.
        #[facet(default, skip_serializing_if = Option::is_none)]
        pub id: Option<String>,

        /// Condition for running this step.
        #[facet(default, skip_serializing_if = Option::is_none, rename = "if")]
        pub if_condition: Option<String>,
    }
}

// =============================================================================
// Helper constructors
// =============================================================================

impl Step {
    /// Create a step that uses a GitHub Action.
    pub fn uses(name: impl Into<String>, action: impl Into<String>) -> Self {
        Self {
            name: Some(name.into()),
            uses: Some(action.into()),
            run: None,
            with: None,
            env: None,
            id: None,
            if_condition: None,
        }
    }

    /// Create a step that runs a shell command.
    pub fn run(name: impl Into<String>, command: impl Into<String>) -> Self {
        Self {
            name: Some(name.into()),
            uses: None,
            run: Some(command.into()),
            with: None,
            env: None,
            id: None,
            if_condition: None,
        }
    }

    /// Add inputs to this step.
    pub fn with_inputs(
        mut self,
        inputs: impl IntoIterator<Item = (impl Into<String>, impl Into<String>)>,
    ) -> Self {
        let map: IndexMap<String, String> = inputs
            .into_iter()
            .map(|(k, v)| (k.into(), v.into()))
            .collect();
        self.with = Some(map);
        self
    }

    /// Add environment variables to this step.
    pub fn with_env(
        mut self,
        env: impl IntoIterator<Item = (impl Into<String>, impl Into<String>)>,
    ) -> Self {
        let map: IndexMap<String, String> =
            env.into_iter().map(|(k, v)| (k.into(), v.into())).collect();
        self.env = Some(map);
        self
    }

    /// Set step ID.
    pub fn with_id(mut self, id: impl Into<String>) -> Self {
        self.id = Some(id.into());
        self
    }
}

impl Job {
    /// Create a new job.
    pub fn new(runs_on: impl Into<String>) -> Self {
        Self {
            name: None,
            runs_on: runs_on.into(),
            container: None,
            needs: None,
            outputs: None,
            if_condition: None,
            steps: Vec::new(),
        }
    }

    /// Set the display name for this job.
    pub fn name(mut self, name: impl Into<String>) -> Self {
        self.name = Some(name.into());
        self
    }

    /// Set the container image for this job.
    pub fn container(mut self, image: impl Into<String>) -> Self {
        self.container = Some(image.into());
        self
    }

    /// Add dependencies to this job.
    pub fn needs(mut self, deps: impl IntoIterator<Item = impl Into<String>>) -> Self {
        self.needs = Some(deps.into_iter().map(Into::into).collect());
        self
    }

    /// Add outputs to this job.
    pub fn outputs(
        mut self,
        outputs: impl IntoIterator<Item = (impl Into<String>, impl Into<String>)>,
    ) -> Self {
        self.outputs = Some(
            outputs
                .into_iter()
                .map(|(k, v)| (k.into(), v.into()))
                .collect(),
        );
        self
    }

    /// Add a condition for this job.
    pub fn when(mut self, condition: impl Into<String>) -> Self {
        self.if_condition = Some(condition.into());
        self
    }

    /// Add steps to this job.
    pub fn steps(mut self, steps: impl IntoIterator<Item = Step>) -> Self {
        self.steps = steps.into_iter().collect();
        self
    }
}

// =============================================================================
// Common step patterns
// =============================================================================

/// Common steps used across jobs.
pub mod common {
    use super::*;

    /// Checkout the repository.
    pub fn checkout() -> Step {
        Step::uses("Checkout", "actions/checkout@v4")
    }

    /// Install Rust toolchain.
    pub fn install_rust() -> Step {
        Step::uses("Install Rust", "dtolnay/rust-toolchain@stable")
    }

    /// Setup Rust cache.
    pub fn rust_cache() -> Step {
        Step::uses("Rust cache", "Swatinem/rust-cache@v2")
    }

    /// Install cargo-nextest.
    pub fn install_nextest() -> Step {
        Step::uses("Install nextest", "taiki-e/install-action@v2")
            .with_inputs([("tool", "cargo-nextest")])
    }

    /// Download grammar sources artifact.
    pub fn download_grammar_sources() -> Step {
        Step::uses("Download grammar sources", "actions/download-artifact@v4")
            .with_inputs([("name", "grammar-sources")])
    }

    /// Extract grammar sources tarball (tar format).
    pub fn extract_grammar_sources_tar() -> Step {
        Step::run("Extract grammar sources", "tar -xvf grammar-sources.tar")
    }

    /// Setup Node.js for npm publishing.
    pub fn setup_node() -> Step {
        Step::uses("Setup Node.js", "actions/setup-node@v4").with_inputs([
            ("node-version", "20"),
            ("registry-url", "https://registry.npmjs.org"),
        ])
    }
}

// =============================================================================
// Workflow builders
// =============================================================================

/// Depot runner sizes.
pub mod runners {
    pub const UBUNTU_4: &str = "depot-ubuntu-24.04-4";
    pub const UBUNTU_32: &str = "depot-ubuntu-24.04-32";
    pub const MACOS: &str = "depot-macos-latest";
}

const CONTAINER: &str = "ghcr.io/bearcove/arborium-plugin-builder:latest";

/// Condition: this is a release (tag push).
const IS_RELEASE: &str = "startsWith(github.ref, 'refs/tags/v')";

/// Configuration for workflow generation.
#[derive(Default)]
pub struct CiConfig {
    /// Plugin build groups (if available)
    pub plugin_groups: Option<PluginGroups>,
}

/// Build the unified CI + Release workflow.
pub fn build_workflow(config: &CiConfig) -> Workflow {
    use common::*;

    let mut jobs = IndexMap::new();

    // =========================================================================
    // STAGE 1: Generate grammar sources
    // =========================================================================
    jobs.insert(
        "generate".into(),
        Job::new(runners::UBUNTU_32)
            .name("Generate")
            .container(CONTAINER)
            .outputs([
                ("version".to_string(), "${{ steps.version.outputs.version }}".to_string()),
                ("is_release".to_string(), "${{ steps.version.outputs.is_release }}".to_string()),
            ])
            .steps([
                checkout(),
                // Parse version from tag (if this is a release)
                Step::run(
                    "Parse version",
                    r#"if [[ "$GITHUB_REF" == refs/tags/v* ]]; then
  VERSION="${GITHUB_REF#refs/tags/v}"
  IS_RELEASE="true"
else
  VERSION="0.0.0-dev"
  IS_RELEASE="false"
fi
echo "version=$VERSION" >> $GITHUB_OUTPUT
echo "is_release=$IS_RELEASE" >> $GITHUB_OUTPUT
echo "Version: $VERSION (release: $IS_RELEASE)""#,
                )
                .with_id("version"),
                // Grammar generation cache
                Step::uses("Restore grammar generation cache", "actions/cache@v4")
                    .with_inputs([
                        ("path", ".cache/arborium"),
                        (
                            "key",
                            "grammar-cache-v3-${{ hashFiles('crates/*/grammar/grammar.js', 'crates/*/grammar/package.json', 'crates/*/common/**') }}",
                        ),
                        ("restore-keys", "grammar-cache-v3-"),
                    ]),
                // Generate with version
                Step::run(
                    "Generate grammar sources",
                    "arborium-xtask gen --version ${{ steps.version.outputs.version }}",
                ),
                // Create tarball for CI jobs (fast tar)
                // Include everything generated: Cargo.toml, src/, and grammar/src/*
                // Also include root Cargo.toml and crates/arborium/Cargo.toml for version consistency
                Step::run(
                    "Create grammar sources tarball",
                    r#"{
  # Root workspace Cargo.toml (has workspace dependency versions)
  echo "Cargo.toml"
  # Main arborium crate Cargo.toml (has dependency versions)
  echo "crates/arborium/Cargo.toml"
  # Grammar crates (only those with a grammar/ directory)
  for d in crates/arborium-*/; do
    if [ -d "$d/grammar" ]; then
      echo "${d}Cargo.toml"
      echo "${d}src"
      echo "${d}grammar/src"
    fi
  done
} > generated_files.txt
tar -cvf grammar-sources.tar -T generated_files.txt"#,
                ),
                Step::uses("Upload grammar sources", "actions/upload-artifact@v4")
                    .with_inputs([
                        ("name", "grammar-sources"),
                        ("path", "grammar-sources.tar"),
                        ("retention-days", "1"),
                    ]),
            ]),
    );

    // =========================================================================
    // STAGE 2: CI Jobs (always run)
    // =========================================================================

    // Test Linux
    jobs.insert(
        "test-linux".into(),
        Job::new(runners::UBUNTU_32)
            .name("Test (Linux)")
            .container(CONTAINER)
            .needs(["generate"])
            .steps([
                checkout(),
                download_grammar_sources(),
                extract_grammar_sources_tar(),
                Step::run("Build", "cargo build --locked --verbose"),
                Step::run("Run tests", "cargo nextest run --locked --verbose"),
                Step::run(
                    "Build with all features",
                    "cargo build --locked --all-features --verbose",
                ),
            ]),
    );

    // Test macOS (no container, needs to install tools)
    jobs.insert(
        "test-macos".into(),
        Job::new(runners::MACOS)
            .name("Test (macOS)")
            .needs(["generate"])
            .steps([
                checkout(),
                download_grammar_sources(),
                extract_grammar_sources_tar(),
                install_rust(),
                rust_cache(),
                install_nextest(),
                Step::run("Build", "cargo build --locked --verbose"),
                Step::run("Run tests", "cargo nextest run --locked --verbose"),
            ]),
    );

    // WASM compatibility check
    jobs.insert(
        "wasm".into(),
        Job::new(runners::UBUNTU_32)
            .name("WASM Compatibility")
            .container(CONTAINER)
            .needs(["generate"])
            .steps([
                checkout(),
                download_grammar_sources(),
                extract_grammar_sources_tar(),
                Step::run(
                    "Build arborium for WASM",
                    "cargo build --locked -p arborium --target wasm32-unknown-unknown",
                ),
                Step::run(
                    "Check for env imports in WASM",
                    r#"found_env_imports=false
for wasm_file in $(find target/wasm32-unknown-unknown -name "*.wasm" -type f); do
  if wasm-objdump -j Import -x "$wasm_file" 2>/dev/null | grep -q '<- env\.'; then
    echo "ERROR: Found env imports in $wasm_file:"
    wasm-objdump -j Import -x "$wasm_file" | grep '<- env\.'
    found_env_imports=true
  fi
done
if [ "$found_env_imports" = true ]; then
  echo "WASM modules should not have env imports - these won't work in the browser"
  exit 1
fi
echo "No env imports found - WASM modules are browser-compatible""#,
                ),
            ]),
    );

    // Clippy
    jobs.insert(
        "clippy".into(),
        Job::new(runners::UBUNTU_32)
            .name("Clippy")
            .container(CONTAINER)
            .needs(["generate"])
            .steps([
                checkout(),
                download_grammar_sources(),
                extract_grammar_sources_tar(),
                Step::run(
                    "Run Clippy",
                    "cargo clippy --locked --all-targets -- -D warnings",
                ),
            ]),
    );

    // Format (no dependency on generate)
    jobs.insert(
        "fmt".into(),
        Job::new(runners::UBUNTU_4)
            .name("Format")
            .container(CONTAINER)
            .steps([
                checkout(),
                Step::run("Check formatting", "cargo fmt --all -- --check"),
                Step::run(
                    "Check CI workflow is up to date",
                    "arborium-xtask ci generate --check",
                ),
            ]),
    );

    // Documentation
    jobs.insert(
        "docs".into(),
        Job::new(runners::UBUNTU_32)
            .name("Documentation")
            .container(CONTAINER)
            .needs(["generate"])
            .steps([
                checkout(),
                download_grammar_sources(),
                extract_grammar_sources_tar(),
                Step::run("Build docs", "cargo doc --locked --no-deps")
                    .with_env([("RUSTDOCFLAGS", "-D warnings")]),
            ]),
    );

    // =========================================================================
    // STAGE 2b: Plugin builds (dynamic groups based on timing)
    // =========================================================================
    let mut plugin_job_ids = Vec::new();

    if let Some(ref groups) = config.plugin_groups {
        let total_groups = groups.groups.len();

        for group in &groups.groups {
            let job_id = format!("build-plugins-{}", group.index);
            let grammars_list = group.grammars.join(" ");
            let display_grammars = group.grammars.join(", ");
            let job_name = format!(
                "Plugins ({}/{}): {}",
                group.index + 1,
                total_groups,
                display_grammars
            );

            plugin_job_ids.push(job_id.clone());

            jobs.insert(
                job_id,
                Job::new(runners::UBUNTU_32)
                    .name(job_name)
                    .container(CONTAINER)
                    .needs(["generate"])
                    .steps([
                        checkout(),
                        download_grammar_sources(),
                        extract_grammar_sources_tar(),
                        Step::run(
                            format!("Build {}", display_grammars),
                            format!("arborium-xtask plugins build {}", grammars_list),
                        ),
                        // Generate npm package.json with version from generate job
                        Step::run(
                            "Generate npm package.json",
                            "arborium-xtask plugins npm --version ${{ needs.generate.outputs.version }}",
                        ),
                        Step::uses("Upload plugins artifact", "actions/upload-artifact@v4")
                            .with_inputs([
                                ("name", format!("plugins-group-{}", group.index)),
                                ("path", "dist/plugins".to_string()),
                                ("retention-days", "7".to_string()),
                            ]),
                    ]),
            );
        }
    }

    // =========================================================================
    // STAGE 3: Publish to crates.io (only on release)
    // =========================================================================
    jobs.insert(
        "publish-crates".into(),
        Job::new(runners::UBUNTU_32)
            .name("Publish crates.io")
            .container(CONTAINER)
            .needs(["generate", "test-linux", "test-macos", "clippy"])
            .when(IS_RELEASE)
            .steps([
                checkout(),
                download_grammar_sources(),
                extract_grammar_sources_tar(),
                Step::run("Publish to crates.io", "arborium-xtask publish crates").with_env([(
                    "CARGO_REGISTRY_TOKEN",
                    "${{ secrets.CARGO_REGISTRY_TOKEN }}",
                )]),
            ]),
    );

    // =========================================================================
    // STAGE 3b: Publish to npm (only on release, after plugins built)
    // =========================================================================
    if !plugin_job_ids.is_empty() {
        let mut npm_needs = vec!["generate".to_string()];
        npm_needs.extend(plugin_job_ids.iter().cloned());

        let mut npm_steps = vec![checkout(), setup_node()];

        // Download all plugin artifacts
        for (i, _) in plugin_job_ids.iter().enumerate() {
            npm_steps.push(
                Step::uses(
                    format!("Download plugins group {}", i),
                    "actions/download-artifact@v4",
                )
                .with_inputs([
                    ("name", format!("plugins-group-{}", i)),
                    ("path", "dist/plugins".to_string()),
                ]),
            );
        }

        npm_steps.extend([
            Step::run(
                "List plugins",
                "find dist/plugins -name 'package.json' | head -20",
            ),
            install_rust(),
            rust_cache(),
            Step::run("Build xtask", "cargo build --release -p xtask"),
            Step::run(
                "Publish to npm",
                "./target/release/xtask publish npm -o dist/plugins",
            )
            .with_env([("NODE_AUTH_TOKEN", "${{ secrets.NPM_TOKEN }}")]),
        ]);

        jobs.insert(
            "publish-npm".into(),
            Job::new("ubuntu-latest")
                .name("Publish npm")
                .needs(npm_needs)
                .when(IS_RELEASE)
                .steps(npm_steps),
        );
    }

    // =========================================================================
    // Build the workflow
    // =========================================================================
    Workflow {
        name: "CI".into(),
        on: On {
            push: Some(PushTrigger {
                branches: Some(vec!["main".into()]),
                tags: Some(vec!["v*".into()]),
            }),
            pull_request: Some(PullRequestTrigger {
                branches: Some(vec!["main".into()]),
            }),
            merge_group: Some(MergeGroupTrigger {}),
            workflow_dispatch: None,
        },
        env: Some(
            [
                ("CARGO_TERM_COLOR", "always"),
                ("CARGO_INCREMENTAL", "0"),
                ("CARGO_PROFILE_TEST_DEBUG", "0"),
            ]
            .into_iter()
            .map(|(k, v)| (k.into(), v.into()))
            .collect(),
        ),
        jobs,
    }
}

// =============================================================================
// Generation
// =============================================================================

use camino::Utf8Path;
use miette::Result;

const GENERATED_HEADER: &str =
    "# GENERATED BY: cargo xtask ci generate\n# DO NOT EDIT - edit xtask/src/ci.rs instead\n";

/// Default number of plugin build groups for CI.
const DEFAULT_NUM_GROUPS: usize = 2;

/// Generate CI workflow files.
pub fn generate(repo_root: &Utf8Path, check: bool) -> Result<()> {
    // Try to load plugin timings if available
    let timings_path = repo_root.join("plugin-timings.json");
    let plugin_groups = if timings_path.exists() {
        match PluginTimings::load(&timings_path) {
            Ok(timings) => {
                println!(
                    "Loaded plugin timings from {} ({} plugins)",
                    timings_path,
                    timings.timings.len()
                );
                Some(PluginGroups::from_timings(&timings, DEFAULT_NUM_GROUPS))
            }
            Err(e) => {
                eprintln!(
                    "Warning: failed to load plugin timings from {}: {}",
                    timings_path, e
                );
                None
            }
        }
    } else {
        println!(
            "No plugin timings file found at {} - skipping plugin jobs",
            timings_path
        );
        println!("Run `cargo xtask plugins build --profile` to generate timings");
        None
    };

    let config = CiConfig { plugin_groups };
    let workflow = build_workflow(&config);
    let yaml_content = format!(
        "{}{}\n",
        GENERATED_HEADER,
        facet_yaml::to_string(&workflow)
            .map_err(|e| miette::miette!("failed to serialize workflow: {}", e))?
    );

    let ci_path = repo_root.join(".github/workflows/ci.yml");

    if check {
        // Check mode: compare with existing file
        let existing = fs_err::read_to_string(&ci_path)
            .map_err(|e| miette::miette!("failed to read {}: {}", ci_path, e))?;

        if existing != yaml_content {
            return Err(miette::miette!(
                "CI workflow is out of date. Run `cargo xtask ci generate` to update."
            ));
        }
        println!("CI workflow is up to date.");
    } else {
        // Generate mode: write the file
        fs_err::write(&ci_path, &yaml_content)
            .map_err(|e| miette::miette!("failed to write {}: {}", ci_path, e))?;

        println!("Written to: {}", ci_path);
    }

    // Delete old release.yml if it exists (now unified into ci.yml)
    let release_path = repo_root.join(".github/workflows/release.yml");
    if release_path.exists() {
        fs_err::remove_file(&release_path)
            .map_err(|e| miette::miette!("failed to remove {}: {}", release_path, e))?;
        println!("Removed old release.yml (now unified into ci.yml)");
    }

    Ok(())
}
